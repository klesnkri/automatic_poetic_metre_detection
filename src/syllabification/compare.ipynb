{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Compare different syllabification/hyphenation approaches"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv\n",
    "import os\n",
    "\n",
    "base_dir = os.getenv(\"WORKING_DIR\")\n",
    "os.chdir(base_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from src.data_loader_and_saver import JSONDataLoaderAndSaver\n",
    "\n",
    "data_loader_and_saver = JSONDataLoaderAndSaver(base_dir, input_data_dir=\"src/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_tokens_one_metre_line_all_metres_recognized.json: loaded 41762 records.\n"
     ]
    }
   ],
   "source": [
    "tokens = data_loader_and_saver.load_data(\"train_tokens_one_metre_line_all_metres_recognized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[['tak', 'z', 'podkroví', 'se', 'všichni', 'vytratili'],\n ['v', 'té', 'doměnce', 'že', 'přece', 'usíná'],\n ['jsou', 'v', 'polích', 'daleko', 'kde', 'hoří', 'úpal', 'bílý'],\n ['a', 'plahočí', 'se', 'známá', 'krajina'],\n ['tam', 'rvou', 'se', 'se', 'zemí', 'a', 'temné', 'chleby', 'jedí'],\n ['tam', 'rvou', 'se', 'po', 'polích', 'a', 'tady', 'šalvěj', 'voní'],\n ['zde', 'černé', 'hodiny', 'jen', 'tik', 'a', 'tak', 'a', 'více', 'nepovědí'],\n ['a', 'po', 'zdi', 'vápenné', 'se', 'řídké', 'mouchy', 'honí'],\n ['a', 'strop', 'ten', 'rayon', 'známý', 'zoufalý'],\n ['jenž', 'oči', 'vysílí', 'a', 'tupá', 'kamna', 'rzivá'],\n ['a', 'okno', 'nesmělé', 'jež', 'zamlklé', 'nechali'],\n ['jímž', 'celé', 'měsíce', 'se', 'nikdo', 'nepodívá'],\n ['než', 'vrátí', 'se', 'snad', 'šalvěj', 'vyvane'],\n ['stín', 'trámů', 'večerní', 'boj', 'muší', 'ukryje'],\n ['on', 'v', 'okno', 'nesmělé', 'se', 'dívat', 'přestane'],\n ['a', 'po', 'klekání', 'teprve', 'se', 'pohnou', 'veřeje']]"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_sampa_tokens_one_metre_line_all_metres_recognized.json: loaded 41762 records.\n"
     ]
    },
    {
     "data": {
      "text/plain": "[['tak', 's', 'potkrovi:', 'sE', 'fSIxJI', 'vItracIlI'],\n ['f', 'tE:', 'domJEnt_sE', 'ZE', 'pP\\\\Et_sE', 'usi:na:'],\n ['jso_u', 'f', 'poli:x', 'dalEko', 'gdE', 'h\\\\oP\\\\i:', 'u:pal', 'bi:li:'],\n ['a', 'plah\\\\ot_Si:', 'sE', 'zna:ma:', 'krajIna'],\n ['tam', 'rvo_u', 'sE', 'sE', 'zEmi:', 'a', 'tEmnE:', 'xlEbI', 'jEJ\\\\i:'],\n ['tam', 'rvo_u', 'sE', 'po', 'poli:x', 'a', 'tadI', 'SalvjEj', 'voJi:'],\n ['zdE',\n  't_SErnE:',\n  'h\\\\oJ\\\\InI',\n  'jEn',\n  'cIk',\n  'a',\n  'tak',\n  'a',\n  'vi:t_sE',\n  'nEpovjEJ\\\\i:'],\n ['a', 'po', 'zJ\\\\I', 'va:pEnE:', 'sE', 'P\\\\i:tkE:', 'mo_uxI', 'h\\\\oJi:'],\n ['a', 'strop', 'tEn', 'rajon', 'zna:mi:', 'zo_ufali:'],\n ['jEnS', 'ot_SI', 'vIsi:li:', 'a', 'tupa:', 'kamna', 'rzIva:'],\n ['a', 'okno', 'nEsmJElE:', 'jES', 'zaml=klE:', 'nExalI'],\n ['ji:mS', 't_sElE:', 'mJEsi:t_sE', 'sE', 'JIgdo', 'nEpoJ\\\\i:va:'],\n ['nES', 'vra:ci:', 'sE', 'snat', 'SalvjEj', 'vIvanE'],\n ['sci:n', 'tra:mu:', 'vEt_SErJi:', 'boj', 'muSi:', 'ukrIjE'],\n ['on', 'f', 'okno', 'nEsmJElE:', 'sE', 'J\\\\i:vat', 'pP\\\\EstanE'],\n ['a', 'po', 'klEka:Ji:', 'tEpr=vE', 'sE', 'poh\\\\no_u', 'vEP\\\\EjE']]"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampa_tokens = data_loader_and_saver.load_data(\"train_sampa_tokens_one_metre_line_all_metres_recognized\")\n",
    "sampa_tokens[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "\n",
    "def get_syllable_cnts(tokens: list, syllabification_func: Callable) -> list:\n",
    "    \"\"\"\n",
    "    Apply syllabification function to every token and return number of syllables in every line.\n",
    "    :param tokens: Tokens to syllabify\n",
    "    :param syllabification_func: Syllabification function\n",
    "    :return: Number of syllables in every line\n",
    "    \"\"\"\n",
    "    return [[np.array([len(syllabification_func(token)) for token in line]) for line in poem] for poem in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[array([1, 1, 3, 1, 2, 4]),\n array([1, 1, 3, 1, 2, 3]),\n array([1, 1, 2, 3, 1, 2, 2, 2]),\n array([1, 3, 1, 2, 3]),\n array([1, 1, 1, 1, 2, 1, 2, 2, 2]),\n array([1, 1, 1, 1, 2, 1, 2, 2, 2]),\n array([1, 2, 3, 1, 1, 1, 1, 1, 2, 4]),\n array([1, 1, 1, 3, 1, 2, 2, 2]),\n array([1, 1, 1, 2, 2, 3]),\n array([1, 2, 3, 1, 2, 2, 2]),\n array([1, 2, 3, 1, 3, 3]),\n array([1, 2, 3, 1, 2, 4]),\n array([1, 2, 1, 1, 2, 3]),\n array([1, 2, 3, 1, 2, 3]),\n array([1, 1, 2, 3, 1, 2, 3]),\n array([1, 1, 3, 3, 1, 2, 3])]"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.kveta.sampa_syllable_parser import SampaSyllableParser\n",
    "\n",
    "sampa_parser = SampaSyllableParser()\n",
    "\n",
    "ref_syllable_cnts = get_syllable_cnts(sampa_tokens, sampa_parser.split_to_syllables)\n",
    "ref_syllable_cnts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[array([1, 1, 3, 1, 2, 5]),\n array([1, 1, 3, 1, 2, 2]),\n array([1, 1, 2, 3, 1, 1, 1, 1]),\n array([1, 3, 1, 2, 3]),\n array([1, 1, 1, 1, 1, 1, 2, 2, 1]),\n array([1, 1, 1, 1, 2, 1, 1, 2, 1]),\n array([1, 2, 3, 1, 1, 1, 1, 1, 1, 4]),\n array([1, 1, 1, 3, 1, 2, 2, 1]),\n array([1, 1, 1, 1, 2, 3]),\n array([1, 1, 3, 1, 1, 2, 2]),\n array([1, 1, 3, 1, 3, 3]),\n array([1, 1, 3, 1, 3, 4]),\n array([1, 2, 1, 1, 2, 3]),\n array([1, 2, 3, 1, 1, 2]),\n array([1, 1, 1, 3, 1, 2, 4]),\n array([1, 1, 3, 3, 1, 2, 3])]"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.syllabification.pat_data_loader import PatDataLoader\n",
    "from src.syllabification.czech_tex_hyphenator import CzechTexHyphenator\n",
    "\n",
    "pat_data_loader = PatDataLoader(base_dir, \"src/syllabification/resources\")\n",
    "patterns = pat_data_loader.load_data(\"csskhyphen.pat\")\n",
    "tex_hyphenator = CzechTexHyphenator(patterns)\n",
    "\n",
    "tex_syllable_cnts = get_syllable_cnts(tokens, tex_hyphenator.hyphenate_word)\n",
    "tex_syllable_cnts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[array([1, 1, 3, 1, 2, 4]),\n array([1, 1, 3, 1, 2, 2]),\n array([1, 1, 2, 3, 1, 1, 1, 1]),\n array([1, 3, 1, 2, 3]),\n array([1, 1, 1, 1, 1, 1, 2, 2, 1]),\n array([1, 1, 1, 1, 2, 1, 1, 2, 1]),\n array([1, 2, 3, 1, 1, 1, 1, 1, 1, 4]),\n array([1, 1, 1, 3, 1, 2, 2, 1]),\n array([1, 1, 1, 1, 2, 3]),\n array([1, 1, 3, 1, 1, 2, 2]),\n array([1, 1, 3, 1, 3, 3]),\n array([1, 1, 3, 1, 2, 4]),\n array([1, 2, 1, 1, 2, 3]),\n array([1, 2, 3, 1, 1, 2]),\n array([1, 1, 1, 3, 1, 2, 3]),\n array([1, 1, 3, 3, 1, 2, 3])]"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.syllabification.tex_heuristics import tex_heuristics\n",
    "\n",
    "tex_heuristics_syllable_cnts = get_syllable_cnts(tokens, lambda x: tex_heuristics(tex_hyphenator.hyphenate_word(x)))\n",
    "tex_heuristics_syllable_cnts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[array([1, 1, 3, 1, 2, 4]),\n array([1, 1, 3, 1, 2, 2]),\n array([1, 1, 2, 3, 1, 2, 1, 2]),\n array([1, 3, 1, 2, 3]),\n array([1, 1, 1, 1, 2, 1, 2, 2, 2]),\n array([1, 1, 1, 1, 2, 1, 2, 2, 2]),\n array([1, 2, 3, 1, 1, 1, 1, 1, 2, 4]),\n array([1, 1, 1, 3, 1, 2, 2, 2]),\n array([1, 1, 1, 1, 2, 3]),\n array([1, 1, 3, 1, 2, 2, 2]),\n array([1, 2, 3, 1, 3, 3]),\n array([1, 2, 3, 1, 2, 4]),\n array([1, 2, 1, 1, 2, 3]),\n array([1, 2, 3, 1, 2, 2]),\n array([1, 1, 2, 3, 1, 2, 3]),\n array([1, 1, 3, 3, 1, 2, 3])]"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyphen\n",
    "\n",
    "pyphen_dict = pyphen.Pyphen(lang=\"cs_CZ\")\n",
    "\n",
    "pyphen_syllable_cnts = get_syllable_cnts(tokens, lambda x: pyphen_dict.inserted(x).split(\"-\"))\n",
    "pyphen_syllable_cnts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_avg_token_syll_cnt_diff(syllabification_approach: str, ref_syllable_cnts: list, pred_syllable_cnts: list) -> float:\n",
    "    \"\"\"\n",
    "    Get the average difference in number of syllables for one token for some syllabification approach.\n",
    "    :param syllabification_approach: Syllabification approach name\n",
    "    :param ref_syllable_cnts: Referential syllable counts\n",
    "    :param pred_syllable_cnts: Predicted syllable counts\n",
    "    :return: Average difference in number of syllables for one token\n",
    "    \"\"\"\n",
    "    token_len_diffs = [x for poem_ref, poem_tex in zip(ref_syllable_cnts, pred_syllable_cnts) for line_ref, line_tex in zip(poem_ref, poem_tex) for x in\n",
    "                       np.abs(np.subtract(line_ref, line_tex))]\n",
    "    avg_token_len_diff = np.average(token_len_diffs)\n",
    "\n",
    "    print(f\"For {syllabification_approach} the average difference in number of syllables for one token is: {avg_token_len_diff:.2f}\")\n",
    "\n",
    "    return avg_token_len_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Czech TEX hyphenation patterns the average difference in number of syllables for one token is: 0.21\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.21010996421526468"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_avg_token_syll_cnt_diff(\"Czech TEX hyphenation patterns\", ref_syllable_cnts, tex_syllable_cnts)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Czech TEX hyphenation patterns with heuristics the average difference in number of syllables for one token is: 0.15\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.14877193439904024"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_avg_token_syll_cnt_diff(\"Czech TEX hyphenation patterns with heuristics\", ref_syllable_cnts, tex_heuristics_syllable_cnts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Pyphen the average difference in number of syllables for one token is: 0.06\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.0577840970166776"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_avg_token_syll_cnt_diff(\"Pyphen\", ref_syllable_cnts, pyphen_syllable_cnts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_avg_percentage_not_ok_tokens_in_line(syllabification_approach: str, ref_syllable_cnts: list, pred_syllable_cnts: list) -> float:\n",
    "    \"\"\"\n",
    "    Get average percentage of incorrectly syllabified tokens in one line.\n",
    "    :param syllabification_approach: Syllabification approach name\n",
    "    :param ref_syllable_cnts: Referential syllable counts\n",
    "    :param pred_syllable_cnts: Predicted syllable counts\n",
    "    :return: Average percentage of incorrectly syllabified tokens in one line\n",
    "    \"\"\"\n",
    "    not_ok_tokens_percentages = [sum(line_ref != line_pred) / len(line_ref) for poem_ref, poem_pred in zip(ref_syllable_cnts, pred_syllable_cnts) for\n",
    "                                 line_ref, line_pred in\n",
    "                                 zip(poem_ref, poem_pred)]\n",
    "    avg_percentage_not_ok_tokens = np.average(not_ok_tokens_percentages)\n",
    "\n",
    "    print(f\"For {syllabification_approach} on average {avg_percentage_not_ok_tokens * 100:.2f} % of tokens in line have incorrect number of syllables\")\n",
    "\n",
    "    return avg_percentage_not_ok_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Czech TEX hyphenation patterns on average 21.63 % of tokens in line have incorrect number of syllables\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.2163037549080216"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_avg_percentage_not_ok_tokens_in_line(\"Czech TEX hyphenation patterns\", ref_syllable_cnts, tex_syllable_cnts)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Czech TEX hyphenation patterns with heuristics on average 15.31 % of tokens in line have incorrect number of syllables\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.1530683181373172"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_avg_percentage_not_ok_tokens_in_line(\"Czech TEX hyphenation patterns with heuristics\", ref_syllable_cnts, tex_heuristics_syllable_cnts)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Pyphen on average 6.18 % of tokens in line have incorrect number of syllables\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.06178628648536689"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_avg_percentage_not_ok_tokens_in_line(\"Pyphen\", ref_syllable_cnts, pyphen_syllable_cnts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: můj, X-SAMPA syllables: ['mu:j'], TeX patterns: ['můj'], TeX heuristics: ['můj'] Pyphen: můj\n",
      "Token: koníček, X-SAMPA syllables: ['ko', 'Ji:', 't_SEk'], TeX patterns: ['ko', 'ní', 'ček'], TeX heuristics: ['ko', 'ní', 'ček'] Pyphen: ko-ní-ček\n",
      "Token: vraný, X-SAMPA syllables: ['vra', 'ni:'], TeX patterns: ['vra', 'ný'], TeX heuristics: ['vra', 'ný'] Pyphen: vra-ný\n",
      "Token: jako, X-SAMPA syllables: ['ja', 'ko'], TeX patterns: ['jako'], TeX heuristics: ['jako'] Pyphen: ja-ko\n",
      "Token: malovaný, X-SAMPA syllables: ['ma', 'lo', 'va', 'ni:'], TeX patterns: ['ma', 'lo', 'va', 'ný'], TeX heuristics: ['ma', 'lo', 'va', 'ný'] Pyphen: ma-lo-va-ný\n",
      "Token: hopsa, X-SAMPA syllables: ['h\\\\o', 'psa'], TeX patterns: ['ho', 'p', 'sa'], TeX heuristics: ['hop', 'sa'] Pyphen: hopsa\n",
      "Token: hejsa, X-SAMPA syllables: ['h\\\\E', 'jsa'], TeX patterns: ['hej', 'sa'], TeX heuristics: ['hej', 'sa'] Pyphen: hejsa\n",
      "Token: hej, X-SAMPA syllables: ['h\\\\Ej'], TeX patterns: ['hej'], TeX heuristics: ['hej'] Pyphen: hej\n",
      "Token: nožky, X-SAMPA syllables: ['no', 'SkI'], TeX patterns: ['nož', 'ky'], TeX heuristics: ['nož', 'ky'] Pyphen: nož-ky\n",
      "Token: pěkné, X-SAMPA syllables: ['pjE', 'knE:'], TeX patterns: ['pěk', 'né'], TeX heuristics: ['pěk', 'né'] Pyphen: pěk-né\n",
      "Token: zdvíhá, X-SAMPA syllables: ['zdvi:', 'h\\\\a:'], TeX patterns: ['zdví', 'há'], TeX heuristics: ['zdví', 'há'] Pyphen: zdví-há\n",
      "Token: ušima, X-SAMPA syllables: ['u', 'SI', 'ma'], TeX patterns: ['uši', 'ma'], TeX heuristics: ['uši', 'ma'] Pyphen: uši-ma\n",
      "Token: si, X-SAMPA syllables: ['sI'], TeX patterns: ['si'], TeX heuristics: ['si'] Pyphen: si\n",
      "Token: stříhá, X-SAMPA syllables: ['stP\\\\i:', 'h\\\\a:'], TeX patterns: ['stří', 'há'], TeX heuristics: ['stří', 'há'] Pyphen: stří-há\n",
      "Token: hopsa, X-SAMPA syllables: ['h\\\\o', 'psa'], TeX patterns: ['ho', 'p', 'sa'], TeX heuristics: ['hop', 'sa'] Pyphen: hopsa\n",
      "Token: hejsa, X-SAMPA syllables: ['h\\\\E', 'jsa'], TeX patterns: ['hej', 'sa'], TeX heuristics: ['hej', 'sa'] Pyphen: hejsa\n",
      "Token: hej, X-SAMPA syllables: ['h\\\\Ej'], TeX patterns: ['hej'], TeX heuristics: ['hej'] Pyphen: hej\n",
      "Token: dlouhá, X-SAMPA syllables: ['dlo_u', 'h\\\\a:'], TeX patterns: ['dlou', 'há'], TeX heuristics: ['dlou', 'há'] Pyphen: dlou-há\n",
      "Token: černá, X-SAMPA syllables: ['t_SE', 'rna:'], TeX patterns: ['čer', 'ná'], TeX heuristics: ['čer', 'ná'] Pyphen: čer-ná\n",
      "Token: hříva, X-SAMPA syllables: ['h\\\\P\\\\i:', 'va'], TeX patterns: ['hří', 'va'], TeX heuristics: ['hří', 'va'] Pyphen: hří-va\n",
      "Token: po, X-SAMPA syllables: ['po'], TeX patterns: ['po'], TeX heuristics: ['po'] Pyphen: po\n",
      "Token: větru, X-SAMPA syllables: ['vjE', 'tru'], TeX patterns: ['vě', 't', 'ru'], TeX heuristics: ['vět', 'ru'] Pyphen: vě-t-ru\n",
      "Token: mu, X-SAMPA syllables: ['mu'], TeX patterns: ['mu'], TeX heuristics: ['mu'] Pyphen: mu\n",
      "Token: splývá, X-SAMPA syllables: ['spli:', 'va:'], TeX patterns: ['splý', 'vá'], TeX heuristics: ['splý', 'vá'] Pyphen: splý-vá\n",
      "Token: hopsa, X-SAMPA syllables: ['h\\\\o', 'psa'], TeX patterns: ['ho', 'p', 'sa'], TeX heuristics: ['hop', 'sa'] Pyphen: hopsa\n",
      "Token: hejsa, X-SAMPA syllables: ['h\\\\E', 'jsa'], TeX patterns: ['hej', 'sa'], TeX heuristics: ['hej', 'sa'] Pyphen: hejsa\n",
      "Token: hej, X-SAMPA syllables: ['h\\\\Ej'], TeX patterns: ['hej'], TeX heuristics: ['hej'] Pyphen: hej\n",
      "Token: podkovky, X-SAMPA syllables: ['po', 'tko', 'fkI'], TeX patterns: ['pod', 'kov', 'ky'], TeX heuristics: ['pod', 'kov', 'ky'] Pyphen: pod-kov-ky\n",
      "Token: mu, X-SAMPA syllables: ['mu'], TeX patterns: ['mu'], TeX heuristics: ['mu'] Pyphen: mu\n",
      "Token: zvoní, X-SAMPA syllables: ['zvo', 'Ji:'], TeX patterns: ['zvo', 'ní'], TeX heuristics: ['zvo', 'ní'] Pyphen: zvo-ní\n",
      "Token: jiskra, X-SAMPA syllables: ['jI', 'skra'], TeX patterns: ['ji', 's', 'k', 'ra'], TeX heuristics: ['jisk', 'ra'] Pyphen: jis-kra\n",
      "Token: jiskru, X-SAMPA syllables: ['jI', 'skru'], TeX patterns: ['ji', 's', 'k', 'ru'], TeX heuristics: ['jisk', 'ru'] Pyphen: jis-kru\n",
      "Token: honí, X-SAMPA syllables: ['h\\\\o', 'Ji:'], TeX patterns: ['honí'], TeX heuristics: ['honí'] Pyphen: ho-ní\n",
      "Token: hopsa, X-SAMPA syllables: ['h\\\\o', 'psa'], TeX patterns: ['ho', 'p', 'sa'], TeX heuristics: ['hop', 'sa'] Pyphen: hopsa\n",
      "Token: hejsa, X-SAMPA syllables: ['h\\\\E', 'jsa'], TeX patterns: ['hej', 'sa'], TeX heuristics: ['hej', 'sa'] Pyphen: hejsa\n",
      "Token: hej, X-SAMPA syllables: ['h\\\\Ej'], TeX patterns: ['hej'], TeX heuristics: ['hej'] Pyphen: hej\n",
      "Token: můj, X-SAMPA syllables: ['mu:j'], TeX patterns: ['můj'], TeX heuristics: ['můj'] Pyphen: můj\n",
      "Token: koníčku, X-SAMPA syllables: ['ko', 'Ji:', 't_Sku'], TeX patterns: ['ko', 'níč', 'ku'], TeX heuristics: ['ko', 'níč', 'ku'] Pyphen: ko-níč-ku\n",
      "Token: vraný, X-SAMPA syllables: ['vra', 'ni:'], TeX patterns: ['vra', 'ný'], TeX heuristics: ['vra', 'ný'] Pyphen: vra-ný\n",
      "Token: jako, X-SAMPA syllables: ['ja', 'ko'], TeX patterns: ['jako'], TeX heuristics: ['jako'] Pyphen: ja-ko\n",
      "Token: malovaný, X-SAMPA syllables: ['ma', 'lo', 'va', 'ni:'], TeX patterns: ['ma', 'lo', 'va', 'ný'], TeX heuristics: ['ma', 'lo', 'va', 'ný'] Pyphen: ma-lo-va-ný\n",
      "Token: hopsa, X-SAMPA syllables: ['h\\\\o', 'psa'], TeX patterns: ['ho', 'p', 'sa'], TeX heuristics: ['hop', 'sa'] Pyphen: hopsa\n",
      "Token: hejsa, X-SAMPA syllables: ['h\\\\E', 'jsa'], TeX patterns: ['hej', 'sa'], TeX heuristics: ['hej', 'sa'] Pyphen: hejsa\n",
      "Token: hej, X-SAMPA syllables: ['h\\\\Ej'], TeX patterns: ['hej'], TeX heuristics: ['hej'] Pyphen: hej\n",
      "Token: až, X-SAMPA syllables: ['aS'], TeX patterns: ['až'], TeX heuristics: ['až'] Pyphen: až\n",
      "Token: tě, X-SAMPA syllables: ['cE'], TeX patterns: ['tě'], TeX heuristics: ['tě'] Pyphen: tě\n",
      "Token: osedláme, X-SAMPA syllables: ['o', 'sE', 'dla:', 'mE'], TeX patterns: ['ose', 'd', 'lá', 'me'], TeX heuristics: ['osed', 'lá', 'me'] Pyphen: osed-lá-me\n",
      "Token: kam, X-SAMPA syllables: ['kam'], TeX patterns: ['kam'], TeX heuristics: ['kam'] Pyphen: kam\n",
      "Token: se, X-SAMPA syllables: ['sE'], TeX patterns: ['se'], TeX heuristics: ['se'] Pyphen: se\n",
      "Token: podíváme, X-SAMPA syllables: ['po', 'J\\\\i:', 'va:', 'mE'], TeX patterns: ['po', 'dí', 'vá', 'me'], TeX heuristics: ['po', 'dí', 'vá', 'me'] Pyphen: po-dí-vá-me\n",
      "Token: hopsa, X-SAMPA syllables: ['h\\\\o', 'psa'], TeX patterns: ['ho', 'p', 'sa'], TeX heuristics: ['hop', 'sa'] Pyphen: hopsa\n",
      "Token: hejsa, X-SAMPA syllables: ['h\\\\E', 'jsa'], TeX patterns: ['hej', 'sa'], TeX heuristics: ['hej', 'sa'] Pyphen: hejsa\n",
      "Token: hej, X-SAMPA syllables: ['h\\\\Ej'], TeX patterns: ['hej'], TeX heuristics: ['hej'] Pyphen: hej\n",
      "Token: rozjedem, X-SAMPA syllables: ['ro', 'zjE', 'dEm'], TeX patterns: ['roz', 'je', 'dem'], TeX heuristics: ['roz', 'je', 'dem'] Pyphen: roz-je-dem\n",
      "Token: se, X-SAMPA syllables: ['sE'], TeX patterns: ['se'], TeX heuristics: ['se'] Pyphen: se\n",
      "Token: v, X-SAMPA syllables: ['f'], TeX patterns: ['v'], TeX heuristics: ['v'] Pyphen: v\n",
      "Token: poli, X-SAMPA syllables: ['po', 'lI'], TeX patterns: ['poli'], TeX heuristics: ['poli'] Pyphen: po-li\n",
      "Token: přes, X-SAMPA syllables: ['pP\\\\Ez'], TeX patterns: ['přes'], TeX heuristics: ['přes'] Pyphen: přes\n",
      "Token: hory, X-SAMPA syllables: ['h\\\\o', 'rI'], TeX patterns: ['hory'], TeX heuristics: ['hory'] Pyphen: ho-ry\n",
      "Token: a, X-SAMPA syllables: ['a'], TeX patterns: ['a'], TeX heuristics: ['a'] Pyphen: a\n",
      "Token: doly, X-SAMPA syllables: ['do', 'lI'], TeX patterns: ['doly'], TeX heuristics: ['doly'] Pyphen: do-ly\n",
      "Token: hopsa, X-SAMPA syllables: ['h\\\\o', 'psa'], TeX patterns: ['ho', 'p', 'sa'], TeX heuristics: ['hop', 'sa'] Pyphen: hopsa\n",
      "Token: hejsa, X-SAMPA syllables: ['h\\\\E', 'jsa'], TeX patterns: ['hej', 'sa'], TeX heuristics: ['hej', 'sa'] Pyphen: hejsa\n",
      "Token: hej, X-SAMPA syllables: ['h\\\\Ej'], TeX patterns: ['hej'], TeX heuristics: ['hej'] Pyphen: hej\n",
      "Token: rozjedem, X-SAMPA syllables: ['ro', 'zjE', 'dEm'], TeX patterns: ['roz', 'je', 'dem'], TeX heuristics: ['roz', 'je', 'dem'] Pyphen: roz-je-dem\n",
      "Token: se, X-SAMPA syllables: ['sE'], TeX patterns: ['se'], TeX heuristics: ['se'] Pyphen: se\n",
      "Token: letem, X-SAMPA syllables: ['lE', 'tEm'], TeX patterns: ['le', 'tem'], TeX heuristics: ['le', 'tem'] Pyphen: le-tem\n",
      "Token: široširým, X-SAMPA syllables: ['SI', 'ro', 'SI', 'ri:m'], TeX patterns: ['ši', 'ro', 'ši', 'rým'], TeX heuristics: ['ši', 'ro', 'ši', 'rým'] Pyphen: ši-ro-ši-rým\n",
      "Token: světem, X-SAMPA syllables: ['svjE', 'tEm'], TeX patterns: ['svě', 'tem'], TeX heuristics: ['svě', 'tem'] Pyphen: svě-tem\n",
      "Token: hopsa, X-SAMPA syllables: ['h\\\\o', 'psa'], TeX patterns: ['ho', 'p', 'sa'], TeX heuristics: ['hop', 'sa'] Pyphen: hopsa\n",
      "Token: hejsa, X-SAMPA syllables: ['h\\\\E', 'jsa'], TeX patterns: ['hej', 'sa'], TeX heuristics: ['hej', 'sa'] Pyphen: hejsa\n",
      "Token: hej, X-SAMPA syllables: ['h\\\\Ej'], TeX patterns: ['hej'], TeX heuristics: ['hej'] Pyphen: hej\n",
      "Token: žeť, X-SAMPA syllables: ['ZEc'], TeX patterns: ['žeť'], TeX heuristics: ['žeť'] Pyphen: žeť\n",
      "Token: se, X-SAMPA syllables: ['sE'], TeX patterns: ['se'], TeX heuristics: ['se'] Pyphen: se\n",
      "Token: rozjedeme, X-SAMPA syllables: ['ro', 'zjE', 'dE', 'mE'], TeX patterns: ['roz', 'je', 'de', 'me'], TeX heuristics: ['roz', 'je', 'de', 'me'] Pyphen: roz-je-de-me\n",
      "Token: kam, X-SAMPA syllables: ['kam'], TeX patterns: ['kam'], TeX heuristics: ['kam'] Pyphen: kam\n",
      "Token: se, X-SAMPA syllables: ['sE'], TeX patterns: ['se'], TeX heuristics: ['se'] Pyphen: se\n",
      "Token: rozjet, X-SAMPA syllables: ['ro', 'zjEt'], TeX patterns: ['roz', 'jet'], TeX heuristics: ['roz', 'jet'] Pyphen: roz-jet\n",
      "Token: chceme, X-SAMPA syllables: ['xt_sE', 'mE'], TeX patterns: ['chce', 'me'], TeX heuristics: ['chce', 'me'] Pyphen: chce-me\n",
      "Token: hopsa, X-SAMPA syllables: ['h\\\\o', 'psa'], TeX patterns: ['ho', 'p', 'sa'], TeX heuristics: ['hop', 'sa'] Pyphen: hopsa\n",
      "Token: hejsa, X-SAMPA syllables: ['h\\\\E', 'jsa'], TeX patterns: ['hej', 'sa'], TeX heuristics: ['hej', 'sa'] Pyphen: hejsa\n",
      "Token: hej, X-SAMPA syllables: ['h\\\\Ej'], TeX patterns: ['hej'], TeX heuristics: ['hej'] Pyphen: hej\n",
      "Token: tak, X-SAMPA syllables: ['tak'], TeX patterns: ['tak'], TeX heuristics: ['tak'] Pyphen: tak\n",
      "Token: můj, X-SAMPA syllables: ['mu:j'], TeX patterns: ['můj'], TeX heuristics: ['můj'] Pyphen: můj\n",
      "Token: vraný, X-SAMPA syllables: ['vra', 'ni:'], TeX patterns: ['vra', 'ný'], TeX heuristics: ['vra', 'ný'] Pyphen: vra-ný\n",
      "Token: koni, X-SAMPA syllables: ['ko', 'JI'], TeX patterns: ['koni'], TeX heuristics: ['koni'] Pyphen: ko-ni\n",
      "Token: ať, X-SAMPA syllables: ['ac'], TeX patterns: ['ať'], TeX heuristics: ['ať'] Pyphen: ať\n",
      "Token: si, X-SAMPA syllables: ['sI'], TeX patterns: ['si'], TeX heuristics: ['si'] Pyphen: si\n",
      "Token: nás, X-SAMPA syllables: ['na:s'], TeX patterns: ['nás'], TeX heuristics: ['nás'] Pyphen: nás\n",
      "Token: kdo, X-SAMPA syllables: ['gdo'], TeX patterns: ['kdo'], TeX heuristics: ['kdo'] Pyphen: kdo\n",
      "Token: honí, X-SAMPA syllables: ['h\\\\o', 'Ji:'], TeX patterns: ['honí'], TeX heuristics: ['honí'] Pyphen: ho-ní\n",
      "Token: hopsa, X-SAMPA syllables: ['h\\\\o', 'psa'], TeX patterns: ['ho', 'p', 'sa'], TeX heuristics: ['hop', 'sa'] Pyphen: hopsa\n",
      "Token: hejsa, X-SAMPA syllables: ['h\\\\E', 'jsa'], TeX patterns: ['hej', 'sa'], TeX heuristics: ['hej', 'sa'] Pyphen: hejsa\n",
      "Token: hej, X-SAMPA syllables: ['h\\\\Ej'], TeX patterns: ['hej'], TeX heuristics: ['hej'] Pyphen: hej\n"
     ]
    }
   ],
   "source": [
    "for sampa_poem, poem in zip(sampa_tokens[:1], tokens[:1]):\n",
    "    for sampa_line, line in zip(sampa_poem, poem):\n",
    "        for sampa_token, token in zip(sampa_line, line):\n",
    "            print(\n",
    "                f\"Token: {token}, X-SAMPA syllables: {sampa_parser.split_to_syllables(sampa_token)}, TeX patterns: {tex_hyphenator.hyphenate_word(token)}, TeX heuristics: {tex_heuristics(tex_hyphenator.hyphenate_word(token))} Pyphen: {pyphen_dict.inserted(token)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}